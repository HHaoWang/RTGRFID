{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-02T08:29:49.515339600Z",
     "start_time": "2024-01-02T08:29:47.126698100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<module 'RTGRFID' from 'E:\\\\Python\\\\RTGRFID\\\\RTGRFID.py'>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn import metrics\n",
    "from torch import nn\n",
    "from openpyxl import Workbook\n",
    "\n",
    "import Dataset\n",
    "import utils\n",
    "import importlib\n",
    "import RTGRFID\n",
    "\n",
    "importlib.reload(RTGRFID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "dataDirectory = r\"C:\\Users\\HHao\\OneDrive\\学习\\研究生\\小论文\\实验数据\\33\"\n",
    "userDataDirectory = r\"C:\\Users\\HHao\\OneDrive\\学习\\研究生\\小论文\\实验数据\\user4\"\n",
    "numberOfRows = 3\n",
    "numberOfCols = 3\n",
    "tagArray2 = np.array([\n",
    "    ['E280689400004013F1505D17', 'E280689400005013F1507117', 'E280689400005013F1506917'],\n",
    "    ['E280689400004013F1507517', 'E280689400004013F155114C', 'E280689400005013F155154C'],\n",
    "    ['E280689400004013F1506117', 'E280689400004013F1506D17', 'E280689400005013F1506517'],\n",
    "])\n",
    "\n",
    "tagArray1 = np.array([\n",
    "    ['E280689400005013F1509918', 'E280689400005013F150B118', 'E280689400005013F150A518'],\n",
    "    ['E280689400004013F1509D18', 'E280689400004013F150B518', 'E280689400005013F150A918'],\n",
    "    ['E280689400005013F1509518', 'E280689400004013F150AD18', 'E280689400004013F150A118'],\n",
    "])\n",
    "\n",
    "seq_len = 90\n",
    "epochs = 150"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T08:29:49.520759400Z",
     "start_time": "2024-01-02T08:29:49.515339600Z"
    }
   },
   "id": "b47dd32addd1ee96"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error tokenizing data. C error: Expected 9 fields in line 1148, saw 10\n",
      "数据集准备完毕\n"
     ]
    }
   ],
   "source": [
    "(train_data, train_labels), (valid_data, valid_labels), classes = Dataset.get_data(dataDirectory, tagArray1, tagArray2,\n",
    "                                                                                   seq_len,\n",
    "                                                                                   0.3)\n",
    "((user_train_data, user_train_labels), (user_valid_data, user_valid_labels),\n",
    " users_classes) = Dataset.get_data(userDataDirectory, tagArray1, tagArray2,\n",
    "                                   seq_len, 0.3)\n",
    "print(\"数据集准备完毕\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T08:30:48.551945700Z",
     "start_time": "2024-01-02T08:29:49.518700100Z"
    }
   },
   "id": "293d920001f37ad3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import RTGRFID\n",
    "\n",
    "importlib.reload(RTGRFID)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "acc = 0\n",
    "model = RTGRFID.RTGRFID(seq_len, len(classes), 2)\n",
    "gesture_criterion = nn.CrossEntropyLoss()\n",
    "user_criterion = nn.CrossEntropyLoss()\n",
    "gesture_criterion_u = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "train_data_len = len(train_data)\n",
    "if len(user_train_data) < train_data_len:\n",
    "    train_data_len = len(user_train_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T08:30:48.767930800Z",
     "start_time": "2024-01-02T08:30:48.551594500Z"
    }
   },
   "id": "de953c066fe098a",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1,  Accuracy:0.2000\n",
      "\t\t User Predict Accuracy:0.0449\n",
      "Epoch:2,  Accuracy:0.4000\n",
      "\t\t User Predict Accuracy:0.1461\n",
      "Epoch:3,  Accuracy:0.3556\n",
      "\t\t User Predict Accuracy:0.1011\n",
      "Epoch:4,  Accuracy:0.4000\n",
      "\t\t User Predict Accuracy:0.1011\n",
      "Epoch:5,  Accuracy:0.4333\n",
      "\t\t User Predict Accuracy:0.1011\n",
      "Epoch:6,  Accuracy:0.6111\n",
      "\t\t User Predict Accuracy:0.1124\n",
      "Epoch:7,  Accuracy:0.5667\n",
      "\t\t User Predict Accuracy:0.0787\n",
      "Epoch:8,  Accuracy:0.6333\n",
      "\t\t User Predict Accuracy:0.1124\n",
      "Epoch:9,  Accuracy:0.7444\n",
      "\t\t User Predict Accuracy:0.1011\n",
      "Epoch:10,  Accuracy:0.6556\n",
      "\t\t User Predict Accuracy:0.0787\n",
      "Epoch:11,  Accuracy:0.1667\n",
      "\t\t User Predict Accuracy:0.0674\n",
      "Epoch:12,  Accuracy:0.2000\n",
      "\t\t User Predict Accuracy:0.0449\n",
      "Epoch:13,  Accuracy:0.6000\n",
      "\t\t User Predict Accuracy:0.1348\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 22\u001B[0m\n\u001B[0;32m     20\u001B[0m     loss_all \u001B[38;5;241m=\u001B[39m gestures_loss_src \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m3.5\u001B[39m \u001B[38;5;241m*\u001B[39m user_loss_src \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m3.5\u001B[39m \u001B[38;5;241m*\u001B[39m user_loss_u\n\u001B[0;32m     21\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m---> 22\u001B[0m     \u001B[43mloss_all\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     23\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     25\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n",
      "File \u001B[1;32mE:\\Python\\envs\\RTGRFID\\Lib\\site-packages\\torch\\_tensor.py:492\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    482\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    483\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    484\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    485\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    490\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    491\u001B[0m     )\n\u001B[1;32m--> 492\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    493\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    494\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Python\\envs\\RTGRFID\\Lib\\site-packages\\torch\\autograd\\__init__.py:251\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    246\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    248\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    249\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    250\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 251\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    252\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    253\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    254\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    257\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    258\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    259\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Python\\envs\\RTGRFID\\Lib\\site-packages\\torch\\autograd\\function.py:276\u001B[0m, in \u001B[0;36mBackwardCFunction.apply\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m    275\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mBackwardCFunction\u001B[39;00m(_C\u001B[38;5;241m.\u001B[39m_FunctionBase, FunctionCtx, _HookMixin):\n\u001B[1;32m--> 276\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs):\n\u001B[0;32m    277\u001B[0m         \u001B[38;5;66;03m# _forward_cls is defined by derived class\u001B[39;00m\n\u001B[0;32m    278\u001B[0m         \u001B[38;5;66;03m# The user should define either backward or vjp but never both.\u001B[39;00m\n\u001B[0;32m    279\u001B[0m         backward_fn \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_cls\u001B[38;5;241m.\u001B[39mbackward  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[0;32m    280\u001B[0m         vjp_fn \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_cls\u001B[38;5;241m.\u001B[39mvjp  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    idx = [i for i in range(train_data_len)]\n",
    "    np.random.shuffle(idx)\n",
    "    model.train()\n",
    "    for i in range(len(idx)):\n",
    "        p = float(i + epoch * train_data_len) / epochs / train_data_len\n",
    "        alpha = 2. / (1. + np.exp(-10 * p)) - 1\n",
    "        x_src = torch.from_numpy(train_data[idx[i]])\n",
    "        gestures_labels_true_src = torch.tensor(train_labels[idx[i]])\n",
    "        user_labels_true_src = torch.tensor([1.0, 0.0])\n",
    "        gestures_labels_pred_src, user_label_pred_src = model(x_src, alpha)\n",
    "        gestures_loss_src = gesture_criterion(gestures_labels_pred_src, gestures_labels_true_src)\n",
    "        user_loss_src = user_criterion(user_label_pred_src, user_labels_true_src)\n",
    "\n",
    "        x_u = torch.from_numpy(user_train_data[idx[i]])\n",
    "        user_label_true_u = torch.tensor([0.0, 1.0])\n",
    "        _, user_label_pred_u = model(x_u, alpha)\n",
    "        user_loss_u = gesture_criterion_u(user_label_pred_u, user_label_true_u)\n",
    "\n",
    "        loss_all = gestures_loss_src + 3.5 * user_loss_src + 3.5 * user_loss_u\n",
    "        optimizer.zero_grad()\n",
    "        loss_all.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_true_labels_g = [utils.one_hot_to_string(label) for label in valid_labels]\n",
    "        y_pred_labels_g = []\n",
    "        for i in range(len(valid_data)):\n",
    "            x_src = torch.Tensor(valid_data[i])\n",
    "            y_pred_g, y_pred_u = model(x_src, torch.tensor([1.0]))\n",
    "            y_pred_labels_g.append(utils.one_hot_to_string(utils.convert_to_one_hot(y_pred_g)))\n",
    "\n",
    "        accuracy_g = metrics.accuracy_score(y_true_labels_g, y_pred_labels_g)\n",
    "        if accuracy_g > acc:\n",
    "            torch.save(model, './model/bestModel.pth')\n",
    "        print(f'Epoch:{epoch + 1:00},  Accuracy:{accuracy_g:.4f}')\n",
    "\n",
    "        user_y_true_labels = [utils.one_hot_to_string(label) for label in user_valid_labels]\n",
    "        user_y_pred_labels = []\n",
    "        for i in range(len(user_valid_data)):\n",
    "            x_src = torch.Tensor(user_valid_data[i])\n",
    "            y_pred_g, y_pred_u = model(x_src, torch.tensor([1.0]))\n",
    "            user_y_pred_labels.append(utils.one_hot_to_string(utils.convert_to_one_hot(y_pred_g)))\n",
    "\n",
    "        accuracy_g = metrics.accuracy_score(user_y_true_labels, user_y_pred_labels)\n",
    "        print(f'\\t\\t User Predict Accuracy:{accuracy_g:.4f}')\n",
    "\n",
    "print('训练结束，最佳Acc:' + str(acc))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T09:10:10.561752300Z",
     "start_time": "2024-01-02T09:09:07.151572400Z"
    }
   },
   "id": "89f348e2402d277b",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torchviz\n",
    "import graphviz"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T08:30:48.833380400Z",
     "start_time": "2024-01-02T08:30:48.767930800Z"
    }
   },
   "id": "16dca67be9dec79b",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'Digraph.gv.pdf'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.from_numpy(train_data[0])\n",
    "out = model(x, torch.tensor([1.0]))\n",
    "g = torchviz.make_dot(out)\n",
    "g.view()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T08:31:04.011263800Z",
     "start_time": "2024-01-02T08:30:48.833380400Z"
    }
   },
   "id": "573c7ea2f1280bd",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "10b57e797d4b0866"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
